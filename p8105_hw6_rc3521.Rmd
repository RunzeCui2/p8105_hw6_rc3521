---
title: "p8105_hw6_rc3521"
author: "Runze Cui"
date: "2022-11-30"
output: github_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)
library(viridis)
library(rstatix)
library(PerformanceAnalytics)
library(modelr)
knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

## Problem 2

We imported the data firstly

```{r, warning = FALSE, message = FALSE}
homicide = read_csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv")
```

Now, we create a city_state variable (e.g. “Baltimore, MD”), and a binary variable indicating whether the homicide is solved. Besides, we omit cities Dallas, TX; Phoenix, AZ; Kansas City, MO; and Tulsa, AL. 

```{r, warning = FALSE}
homicide_df = 
  homicide %>% 
  janitor::clean_names() %>%
   mutate(
     city_state = str_c(city, state, sep = ", "),
     resolved = if_else(disposition %in% "Closed by arrest", 1, 0),
     reported_date = as.Date(as.character(reported_date), format = "%Y%m%d"),
     victim_age = as.numeric(victim_age),
     victim_race = fct_relevel(victim_race, "White")
    ) %>%
  filter(!city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"),
         victim_race %in% c("White", "Black")) %>%
  relocate(city_state)
```

Fit the logistic regression by `glm` function and obtain required measures by `broom::tidy` function

```{r}
baltimore_log = 
  homicide_df %>%
  filter(city_state == "Baltimore, MD") %>%
  glm(resolved ~ victim_age + victim_race + victim_sex, data = ., family = binomial())

## get estimates and confidence interval of the adjusted odds ratio
baltimore_log = 
  baltimore_log %>% 
  broom::tidy(conf.int = TRUE, conf.level = 0.95) %>% 
  mutate(OR = exp(estimate),
         ci_lower = exp(conf.low),
         ci_upper = exp(conf.high)) %>%
  select(term, log_OR = estimate, OR, ci_lower, ci_upper, p.value)

baltimore_log %>% 
  knitr::kable(digits = 3)
```

Based on the results above, keeping all other variables fixed, in Baltimore, MD, and we observed that homicides in which the victim is male are less likely to be resolved than those in which the victim is female.


Now, run the logistic model for each city of data and obtain the adjusted odd ratios and confidential intervals

```{r, warning = F}
all_log = 
  homicide_df %>% 
  select(city_state, victim_race, victim_age, victim_sex, resolved) %>%
  nest(data = -city_state) %>% 
  mutate(
    models = map(data, ~glm(resolved ~ victim_age + victim_race + victim_sex, data = ., family = binomial())),
    results = map(models, ~broom::tidy(., conf.int = TRUE, conf.level = 0.95))) %>% 
  select(-data, -models) %>%
  unnest(results) 
  
```

Generate a table for all of these data

```{r, warning = FALSE, message=FALSE}
all_log =
  all_log %>% 
  mutate(
         OR = exp(estimate),
         ci_lower = exp(conf.low),
         ci_upper = exp(conf.high)) %>%
    select(city_state, term, log_OR = estimate, OR, ci_lower, ci_upper, p.value) %>% 
  filter(term == "victim_sexMale")

 all_log %>% 
  knitr::kable(digits = 3)
```

Finally, we need to create a plot to show the estimated ORs and confidential intervals for each city. Organize it based on the estimated OR and comment the plot properly.

```{r, fig.height=8, fig.width = 12}
all_log %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR)) + 
  geom_point() +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper)) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
   labs(
    title = "Adjusted OR and CI for Resolving Homicides Based on Victims' Gender",
    x = "City, State",
    y = "Odds Ratio"
  )
```


Clearly, assuming all other variables unchanged, homicides in which the victim is male are relatively less likely to be resolved than those in which the victim is female generally. Specifically, for most of cities, the OR is less than 1, representing a decreasing trend of odds of resolving a homicide when the victim is male compared with female. Some city like Albequerque, Stockton, and Fresno, on the other hands, shows a increased odds of resolving a homicide when the victim is male compared with female. 

## Problem 3

Loading and processing the data

```{r, message = FALSE, warning = FALSE}
birthweight_df = 
  read_csv("data/birthweight.csv") %>% 
  janitor::clean_names() %>%
  mutate(
        across(.cols = c(babysex, frace, malform, mrace), as.factor)
        ) %>%
  mutate(
    mrace = recode(mrace, 
                   `1` = "White", 
                   `2` = "Black", 
                   `3` = "Asian", 
                   `4` = "Puerto Rican", 
                   `8` = "Other"),
    frace = recode(frace, 
                   `1` = "White", 
                   `2` = "Black", 
                   `3` = "Asian", 
                   `4` = "Puerto Rican", 
                   `8` = "Other", 
                   `9` = "Unknown"),
    babysex = recode(babysex, 
                     `1` = "Male", 
                     `2` = "Female"),
    malform = ifelse(malform == "0", "absent","present")
    ) %>% 
  mutate(
    frace = fct_relevel(frace, "White"),
    mrace = fct_relevel(mrace, "White"),
    babysex = fct_relevel(babysex,"Female")
         ) %>% 
  select(bwt,everything())

head(birthweight_df, 10)
```

Propose a regression model for `birthweight.` This model may be based on a hypothesized structure for the factors that underly `birthweight`, on a data-driven model-building process, or a combination of the two.

First, we need to determine which model is proper in this problem

`m_1` represents the full model

```{r}
m_1 = 
  lm(bwt ~., data = birthweight_df)
summary(m_1)

```

Now, we check select the variables and determine which predictors are dropped and which can be reserved. In the part, I use `MASS` package to do stepwise process for model selection. And `broom::tidy` can be used to show the predictors which we reserved after stepwise model selection.

```{r}
m_2 = MASS::stepAIC(m_1, direction = "both", trace = FALSE)
broom::tidy(m_2) 
```

Then, draw a plot of model residuals and fitted values

```{r, message = FALSE, warning = FALSE}
birthweight_df %>% 
  add_residuals(m_2) %>% 
  add_predictions(m_2) %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(
    x = "Fitted values",
    y = "Residuals",
    title = "Model residuals vs fitted values"
  )
```

Then, we do cross validation. Note: `model_1` is the model what we choose above. 

```{r warning = FALSE}
cv_df = 
  crossv_mc(birthweight_df, 2000) %>% 
  mutate(
    train = map(train, as_tibble), 
    test = map(test, as_tibble))

cv_df_1 =
  cv_df %>% 
  mutate(
    model_1  = map(train, ~lm(bwt ~ babysex + bhead + blength + 
                                delwt + fincome + gaweeks + 
                                mheight + mrace + parity + 
                                ppwt + smoken, data = .x)),
    model_2  = map(train, ~lm(bwt ~ gaweeks + blength, data = .x)),
    model_3  = map(train, ~lm(bwt ~ bhead + blength + babysex, data = .x))) %>% 
  mutate(
    rmse_1 = map2_dbl(model_1, test, ~rmse(model = .x, data = .y)),
    rmse_2 = map2_dbl(model_2, test, ~rmse(model = .x, data = .y)),
    rmse_3 = map2_dbl(model_3, test, ~rmse(model = .x, data = .y)))
  
```

Plotting

```{r, warning = FALSE}
cv_df_1 %>% 
  select(starts_with("rmse")) %>% 
    pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
    mutate(model = fct_inorder(model)) %>% 
    ggplot(aes(x = model, y = rmse)) + 
    geom_violin(aes(fill = model))
```

Therefore, the `model_1` has lower RMSE value and it should be more optimal than other 2 models. 



